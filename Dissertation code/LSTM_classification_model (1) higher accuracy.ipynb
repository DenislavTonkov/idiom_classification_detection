{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:26.695309Z",
     "start_time": "2022-05-24T15:33:15.142040Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import ast\n",
    "from tensorflow.keras import layers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:35.427310Z",
     "start_time": "2022-05-24T15:33:26.697307Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('legit_ones_5l_vectors.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:35.459316Z",
     "start_time": "2022-05-24T15:33:35.430311Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "df['label']=encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:39.199305Z",
     "start_time": "2022-05-24T15:33:35.464313Z"
    }
   },
   "outputs": [],
   "source": [
    "# max lenth of is 45 for idioms\n",
    "r=[]\n",
    "for i in range(df.shape[0]):\n",
    "    x = ast.literal_eval(df['all_idiom_5l_each_word'][i])\n",
    "    r.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:39.451342Z",
     "start_time": "2022-05-24T15:33:39.202311Z"
    }
   },
   "outputs": [],
   "source": [
    "for j in range(len(r)):\n",
    "    for i in range(45-len(r[j])):\n",
    "        r[j].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:39.943345Z",
     "start_time": "2022-05-24T15:33:39.455315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.706041</td>\n",
       "      <td>-2.400280</td>\n",
       "      <td>1.441445</td>\n",
       "      <td>-1.572476</td>\n",
       "      <td>3.178705</td>\n",
       "      <td>-0.989343</td>\n",
       "      <td>-2.965439</td>\n",
       "      <td>-1.656484</td>\n",
       "      <td>-0.818308</td>\n",
       "      <td>2.228827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.911975</td>\n",
       "      <td>0.466270</td>\n",
       "      <td>-0.744243</td>\n",
       "      <td>-1.081924</td>\n",
       "      <td>-2.690621</td>\n",
       "      <td>-1.982522</td>\n",
       "      <td>-1.727190</td>\n",
       "      <td>-2.760475</td>\n",
       "      <td>-1.732051</td>\n",
       "      <td>-0.339831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.264573</td>\n",
       "      <td>0.961804</td>\n",
       "      <td>3.210402</td>\n",
       "      <td>-0.762324</td>\n",
       "      <td>0.473270</td>\n",
       "      <td>-2.267075</td>\n",
       "      <td>-0.246786</td>\n",
       "      <td>2.582364</td>\n",
       "      <td>0.359696</td>\n",
       "      <td>0.347087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.912891</td>\n",
       "      <td>0.240082</td>\n",
       "      <td>2.398815</td>\n",
       "      <td>0.254071</td>\n",
       "      <td>0.138524</td>\n",
       "      <td>1.709964</td>\n",
       "      <td>0.659743</td>\n",
       "      <td>0.193390</td>\n",
       "      <td>0.474542</td>\n",
       "      <td>2.163204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.461462</td>\n",
       "      <td>-0.827581</td>\n",
       "      <td>-1.058371</td>\n",
       "      <td>-2.533165</td>\n",
       "      <td>2.605412</td>\n",
       "      <td>-2.262347</td>\n",
       "      <td>5.604730</td>\n",
       "      <td>-0.617172</td>\n",
       "      <td>0.278911</td>\n",
       "      <td>0.153157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24805</th>\n",
       "      <td>-1.573374</td>\n",
       "      <td>4.653001</td>\n",
       "      <td>1.094262</td>\n",
       "      <td>-2.634780</td>\n",
       "      <td>2.059686</td>\n",
       "      <td>0.240416</td>\n",
       "      <td>0.289104</td>\n",
       "      <td>-0.246852</td>\n",
       "      <td>-0.731543</td>\n",
       "      <td>0.361849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24806</th>\n",
       "      <td>0.197703</td>\n",
       "      <td>2.343588</td>\n",
       "      <td>2.757625</td>\n",
       "      <td>-0.619617</td>\n",
       "      <td>1.132591</td>\n",
       "      <td>0.914919</td>\n",
       "      <td>0.469362</td>\n",
       "      <td>3.042929</td>\n",
       "      <td>-0.427493</td>\n",
       "      <td>3.312955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24807</th>\n",
       "      <td>-2.161072</td>\n",
       "      <td>2.054279</td>\n",
       "      <td>2.774971</td>\n",
       "      <td>1.189215</td>\n",
       "      <td>4.888242</td>\n",
       "      <td>-0.735887</td>\n",
       "      <td>1.086011</td>\n",
       "      <td>2.906706</td>\n",
       "      <td>0.553608</td>\n",
       "      <td>2.586283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24808</th>\n",
       "      <td>4.936450</td>\n",
       "      <td>7.411347</td>\n",
       "      <td>1.970084</td>\n",
       "      <td>-2.220847</td>\n",
       "      <td>-1.292620</td>\n",
       "      <td>0.453957</td>\n",
       "      <td>4.809259</td>\n",
       "      <td>2.020978</td>\n",
       "      <td>-3.288856</td>\n",
       "      <td>-2.603212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24809</th>\n",
       "      <td>1.145146</td>\n",
       "      <td>-0.745880</td>\n",
       "      <td>0.171952</td>\n",
       "      <td>-1.818744</td>\n",
       "      <td>3.333541</td>\n",
       "      <td>-4.011673</td>\n",
       "      <td>1.990396</td>\n",
       "      <td>-0.458345</td>\n",
       "      <td>-3.002555</td>\n",
       "      <td>5.025704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24810 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.706041 -2.400280  1.441445 -1.572476  3.178705 -0.989343 -2.965439   \n",
       "1     -2.911975  0.466270 -0.744243 -1.081924 -2.690621 -1.982522 -1.727190   \n",
       "2     -1.264573  0.961804  3.210402 -0.762324  0.473270 -2.267075 -0.246786   \n",
       "3      3.912891  0.240082  2.398815  0.254071  0.138524  1.709964  0.659743   \n",
       "4      0.461462 -0.827581 -1.058371 -2.533165  2.605412 -2.262347  5.604730   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24805 -1.573374  4.653001  1.094262 -2.634780  2.059686  0.240416  0.289104   \n",
       "24806  0.197703  2.343588  2.757625 -0.619617  1.132591  0.914919  0.469362   \n",
       "24807 -2.161072  2.054279  2.774971  1.189215  4.888242 -0.735887  1.086011   \n",
       "24808  4.936450  7.411347  1.970084 -2.220847 -1.292620  0.453957  4.809259   \n",
       "24809  1.145146 -0.745880  0.171952 -1.818744  3.333541 -4.011673  1.990396   \n",
       "\n",
       "              7         8         9  ...   36   37   38   39   40   41   42  \\\n",
       "0     -1.656484 -0.818308  2.228827  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1     -2.760475 -1.732051 -0.339831  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      2.582364  0.359696  0.347087  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      0.193390  0.474542  2.163204  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     -0.617172  0.278911  0.153157  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "24805 -0.246852 -0.731543  0.361849  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "24806  3.042929 -0.427493  3.312955  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "24807  2.906706  0.553608  2.586283  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "24808  2.020978 -3.288856 -2.603212  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "24809 -0.458345 -3.002555  5.025704  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        43   44  y  \n",
       "0      0.0  0.0  0  \n",
       "1      0.0  0.0  0  \n",
       "2      0.0  0.0  0  \n",
       "3      0.0  0.0  0  \n",
       "4      0.0  0.0  0  \n",
       "...    ...  ... ..  \n",
       "24805  0.0  0.0  0  \n",
       "24806  0.0  0.0  1  \n",
       "24807  0.0  0.0  0  \n",
       "24808  0.0  0.0  0  \n",
       "24809  0.0  0.0  0  \n",
       "\n",
       "[24810 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=pd.concat([pd.DataFrame(r),pd.DataFrame(list(df['label']),columns=['y'])],axis=1)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:39.974346Z",
     "start_time": "2022-05-24T15:33:39.948347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16742, 46)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idiom=data1[(data1['y']==0)&(data1.index<20000)].reset_index(drop=True)\n",
    "train_idiom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:40.006322Z",
     "start_time": "2022-05-24T15:33:39.977309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16742, 46)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_literal=data1[(data1['y']==1)&(data1.index<20000)].reset_index(drop=True)\n",
    "train_literal_bias=pd.DataFrame()\n",
    "train_literal_bias=pd.concat([train_literal_bias,train_literal,train_literal,train_literal,train_literal,train_literal,train_literal[0:452]],axis=0)\n",
    "train_literal_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:40.070314Z",
     "start_time": "2022-05-24T15:33:40.009309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200794</td>\n",
       "      <td>1.746465</td>\n",
       "      <td>-2.469869</td>\n",
       "      <td>-2.413901</td>\n",
       "      <td>3.175566</td>\n",
       "      <td>2.754219</td>\n",
       "      <td>3.479995</td>\n",
       "      <td>0.845903</td>\n",
       "      <td>-2.629498</td>\n",
       "      <td>6.356821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.471947</td>\n",
       "      <td>0.251455</td>\n",
       "      <td>-0.852516</td>\n",
       "      <td>0.875013</td>\n",
       "      <td>0.907998</td>\n",
       "      <td>-5.074784</td>\n",
       "      <td>-1.981690</td>\n",
       "      <td>-1.358121</td>\n",
       "      <td>1.145342</td>\n",
       "      <td>2.465438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.398004</td>\n",
       "      <td>-1.787525</td>\n",
       "      <td>0.093280</td>\n",
       "      <td>-1.910716</td>\n",
       "      <td>3.612620</td>\n",
       "      <td>-2.922696</td>\n",
       "      <td>-0.794799</td>\n",
       "      <td>-0.683657</td>\n",
       "      <td>2.075389</td>\n",
       "      <td>1.013283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.163574</td>\n",
       "      <td>-2.277607</td>\n",
       "      <td>0.512381</td>\n",
       "      <td>-4.007491</td>\n",
       "      <td>-0.503701</td>\n",
       "      <td>-2.844902</td>\n",
       "      <td>-4.045784</td>\n",
       "      <td>-0.653298</td>\n",
       "      <td>-2.134147</td>\n",
       "      <td>0.967743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.647244</td>\n",
       "      <td>1.636005</td>\n",
       "      <td>-0.747913</td>\n",
       "      <td>-1.711509</td>\n",
       "      <td>4.521041</td>\n",
       "      <td>0.742066</td>\n",
       "      <td>4.090480</td>\n",
       "      <td>-0.664268</td>\n",
       "      <td>-1.796380</td>\n",
       "      <td>5.209273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>-2.845213</td>\n",
       "      <td>3.246986</td>\n",
       "      <td>-0.339011</td>\n",
       "      <td>5.081264</td>\n",
       "      <td>2.669884</td>\n",
       "      <td>-4.743480</td>\n",
       "      <td>4.011475</td>\n",
       "      <td>-1.459684</td>\n",
       "      <td>6.556819</td>\n",
       "      <td>1.923460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>-1.996757</td>\n",
       "      <td>0.283110</td>\n",
       "      <td>-1.624118</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.498333</td>\n",
       "      <td>-0.903049</td>\n",
       "      <td>2.904166</td>\n",
       "      <td>-0.832911</td>\n",
       "      <td>4.955476</td>\n",
       "      <td>0.796886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>-1.657352</td>\n",
       "      <td>2.667484</td>\n",
       "      <td>2.989386</td>\n",
       "      <td>-2.029863</td>\n",
       "      <td>2.197638</td>\n",
       "      <td>-0.436760</td>\n",
       "      <td>-0.626940</td>\n",
       "      <td>3.460732</td>\n",
       "      <td>-0.748058</td>\n",
       "      <td>4.563299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>-1.194216</td>\n",
       "      <td>2.536058</td>\n",
       "      <td>1.035588</td>\n",
       "      <td>0.031019</td>\n",
       "      <td>-0.470849</td>\n",
       "      <td>-2.807090</td>\n",
       "      <td>1.284870</td>\n",
       "      <td>-0.393757</td>\n",
       "      <td>0.377447</td>\n",
       "      <td>-0.401311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-1.105914</td>\n",
       "      <td>1.593325</td>\n",
       "      <td>3.017853</td>\n",
       "      <td>-1.951643</td>\n",
       "      <td>-1.316843</td>\n",
       "      <td>-0.715635</td>\n",
       "      <td>-0.531083</td>\n",
       "      <td>-0.207648</td>\n",
       "      <td>-0.779627</td>\n",
       "      <td>0.666357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.200794  1.746465 -2.469869 -2.413901  3.175566  2.754219  3.479995   \n",
       "1   -4.471947  0.251455 -0.852516  0.875013  0.907998 -5.074784 -1.981690   \n",
       "2   -0.398004 -1.787525  0.093280 -1.910716  3.612620 -2.922696 -0.794799   \n",
       "3   -3.163574 -2.277607  0.512381 -4.007491 -0.503701 -2.844902 -4.045784   \n",
       "4   -1.647244  1.636005 -0.747913 -1.711509  4.521041  0.742066  4.090480   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "447 -2.845213  3.246986 -0.339011  5.081264  2.669884 -4.743480  4.011475   \n",
       "448 -1.996757  0.283110 -1.624118  0.087100  0.498333 -0.903049  2.904166   \n",
       "449 -1.657352  2.667484  2.989386 -2.029863  2.197638 -0.436760 -0.626940   \n",
       "450 -1.194216  2.536058  1.035588  0.031019 -0.470849 -2.807090  1.284870   \n",
       "451 -1.105914  1.593325  3.017853 -1.951643 -1.316843 -0.715635 -0.531083   \n",
       "\n",
       "            7         8         9  ...   36   37   38   39   40   41   42  \\\n",
       "0    0.845903 -2.629498  6.356821  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1   -1.358121  1.145342  2.465438  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2   -0.683657  2.075389  1.013283  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3   -0.653298 -2.134147  0.967743  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4   -0.664268 -1.796380  5.209273  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "..        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "447 -1.459684  6.556819  1.923460  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "448 -0.832911  4.955476  0.796886  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "449  3.460732 -0.748058  4.563299  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "450 -0.393757  0.377447 -0.401311  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "451 -0.207648 -0.779627  0.666357  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      43   44  y  \n",
       "0    0.0  0.0  1  \n",
       "1    0.0  0.0  1  \n",
       "2    0.0  0.0  1  \n",
       "3    0.0  0.0  1  \n",
       "4    0.0  0.0  1  \n",
       "..   ...  ... ..  \n",
       "447  0.0  0.0  1  \n",
       "448  0.0  0.0  1  \n",
       "449  0.0  0.0  1  \n",
       "450  0.0  0.0  1  \n",
       "451  0.0  0.0  1  \n",
       "\n",
       "[452 rows x 46 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_literal[0:452]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:40.086308Z",
     "start_time": "2022-05-24T15:33:40.074314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16742-3258*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:40.148417Z",
     "start_time": "2022-05-24T15:33:40.090312Z"
    }
   },
   "outputs": [],
   "source": [
    "train_idiom=data1[(data1['y']==0)&(data1.index<20000)].reset_index(drop=True)[0:3258]\n",
    "train_literal=data1[(data1['y']==1)&(data1.index<20000)].reset_index(drop=True)[0:3258]\n",
    "train=pd.concat([train_idiom,train_literal],axis=0).reset_index(drop=True)\n",
    "train= train.sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "test_literal=data1[(data1['y']==1)&(data1.index>20000)].reset_index(drop=True)\n",
    "test_idiom=data1[(data1['y']==0)&(data1.index>20000)].reset_index(drop=True)[0:769]\n",
    "test=pd.concat([test_idiom,test_literal],axis=0).reset_index(drop=True)\n",
    "test=test.sample(frac = 1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:40.449309Z",
     "start_time": "2022-05-24T15:33:40.151308Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x_train=train.iloc[:,:45]\n",
    "y_train=train['y']\n",
    "x_test=test.iloc[:,:45]\n",
    "y_test=test['y']\n",
    "\n",
    "\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:38:13.580327Z",
     "start_time": "2022-05-24T15:38:13.559326Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:42:38.604368Z",
     "start_time": "2022-05-24T15:42:38.595366Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:42:58.910792Z",
     "start_time": "2022-05-24T15:42:58.883795Z"
    }
   },
   "outputs": [],
   "source": [
    "X=data1.iloc[:,0:45]\n",
    "y=data1.iloc[:,45:46]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:43:02.104877Z",
     "start_time": "2022-05-24T15:43:02.099920Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train=np.reshape(x_train,(x_train.shape[0],1,x_train.shape[1]))\n",
    "x_test=np.reshape(x_test,(x_test.shape[0],1,x_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T16:00:18.319229Z",
     "start_time": "2022-05-24T15:43:04.720904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 1, 512)            618496    \n",
      "_________________________________________________________________\n",
      "lstm_layer2 (LSTM)           (None, 128)               328192    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                1950      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 957,215\n",
      "Trainable params: 957,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "260/260 - 5s - loss: 0.3824 - accuracy: 0.8495\n",
      "Epoch 2/200\n",
      "260/260 - 5s - loss: 0.3402 - accuracy: 0.8646\n",
      "Epoch 3/200\n",
      "260/260 - 5s - loss: 0.3155 - accuracy: 0.8749\n",
      "Epoch 4/200\n",
      "260/260 - 5s - loss: 0.2988 - accuracy: 0.8812\n",
      "Epoch 5/200\n",
      "260/260 - 5s - loss: 0.2873 - accuracy: 0.8853\n",
      "Epoch 6/200\n",
      "260/260 - 5s - loss: 0.2747 - accuracy: 0.8921\n",
      "Epoch 7/200\n",
      "260/260 - 6s - loss: 0.2648 - accuracy: 0.8970\n",
      "Epoch 8/200\n",
      "260/260 - 6s - loss: 0.2546 - accuracy: 0.9031\n",
      "Epoch 9/200\n",
      "260/260 - 5s - loss: 0.2439 - accuracy: 0.9061\n",
      "Epoch 10/200\n",
      "260/260 - 5s - loss: 0.2344 - accuracy: 0.9105\n",
      "Epoch 11/200\n",
      "260/260 - 5s - loss: 0.2272 - accuracy: 0.9128\n",
      "Epoch 12/200\n",
      "260/260 - 5s - loss: 0.2201 - accuracy: 0.9139\n",
      "Epoch 13/200\n",
      "260/260 - 5s - loss: 0.2101 - accuracy: 0.9179\n",
      "Epoch 14/200\n",
      "260/260 - 5s - loss: 0.2030 - accuracy: 0.9221\n",
      "Epoch 15/200\n",
      "260/260 - 5s - loss: 0.1977 - accuracy: 0.9252\n",
      "Epoch 16/200\n",
      "260/260 - 5s - loss: 0.1886 - accuracy: 0.9280\n",
      "Epoch 17/200\n",
      "260/260 - 5s - loss: 0.1835 - accuracy: 0.9304\n",
      "Epoch 18/200\n",
      "260/260 - 6s - loss: 0.1764 - accuracy: 0.9314\n",
      "Epoch 19/200\n",
      "260/260 - 6s - loss: 0.1692 - accuracy: 0.9354\n",
      "Epoch 20/200\n",
      "260/260 - 5s - loss: 0.1627 - accuracy: 0.9383\n",
      "Epoch 21/200\n",
      "260/260 - 4s - loss: 0.1553 - accuracy: 0.9404\n",
      "Epoch 22/200\n",
      "260/260 - 5s - loss: 0.1477 - accuracy: 0.9440\n",
      "Epoch 23/200\n",
      "260/260 - 4s - loss: 0.1426 - accuracy: 0.9447\n",
      "Epoch 24/200\n",
      "260/260 - 4s - loss: 0.1359 - accuracy: 0.9481\n",
      "Epoch 25/200\n",
      "260/260 - 4s - loss: 0.1288 - accuracy: 0.9495\n",
      "Epoch 26/200\n",
      "260/260 - 5s - loss: 0.1246 - accuracy: 0.9536\n",
      "Epoch 27/200\n",
      "260/260 - 4s - loss: 0.1175 - accuracy: 0.9557\n",
      "Epoch 28/200\n",
      "260/260 - 5s - loss: 0.1112 - accuracy: 0.9576\n",
      "Epoch 29/200\n",
      "260/260 - 4s - loss: 0.1046 - accuracy: 0.9615\n",
      "Epoch 30/200\n",
      "260/260 - 4s - loss: 0.1036 - accuracy: 0.9619\n",
      "Epoch 31/200\n",
      "260/260 - 4s - loss: 0.0983 - accuracy: 0.9643\n",
      "Epoch 32/200\n",
      "260/260 - 4s - loss: 0.0934 - accuracy: 0.9660\n",
      "Epoch 33/200\n",
      "260/260 - 4s - loss: 0.0909 - accuracy: 0.9692\n",
      "Epoch 34/200\n",
      "260/260 - 4s - loss: 0.0833 - accuracy: 0.9699\n",
      "Epoch 35/200\n",
      "260/260 - 4s - loss: 0.0817 - accuracy: 0.9709\n",
      "Epoch 36/200\n",
      "260/260 - 4s - loss: 0.0773 - accuracy: 0.9729\n",
      "Epoch 37/200\n",
      "260/260 - 4s - loss: 0.0698 - accuracy: 0.9754\n",
      "Epoch 38/200\n",
      "260/260 - 5s - loss: 0.0702 - accuracy: 0.9769\n",
      "Epoch 39/200\n",
      "260/260 - 6s - loss: 0.0644 - accuracy: 0.9780\n",
      "Epoch 40/200\n",
      "260/260 - 6s - loss: 0.0628 - accuracy: 0.9797\n",
      "Epoch 41/200\n",
      "260/260 - 5s - loss: 0.0573 - accuracy: 0.9826\n",
      "Epoch 42/200\n",
      "260/260 - 6s - loss: 0.0567 - accuracy: 0.9807\n",
      "Epoch 43/200\n",
      "260/260 - 5s - loss: 0.0603 - accuracy: 0.9798\n",
      "Epoch 44/200\n",
      "260/260 - 5s - loss: 0.0544 - accuracy: 0.9827\n",
      "Epoch 45/200\n",
      "260/260 - 4s - loss: 0.0547 - accuracy: 0.9832\n",
      "Epoch 46/200\n",
      "260/260 - 4s - loss: 0.0502 - accuracy: 0.9845\n",
      "Epoch 47/200\n",
      "260/260 - 6s - loss: 0.0498 - accuracy: 0.9848\n",
      "Epoch 48/200\n",
      "260/260 - 6s - loss: 0.0475 - accuracy: 0.9851\n",
      "Epoch 49/200\n",
      "260/260 - 6s - loss: 0.0459 - accuracy: 0.9867\n",
      "Epoch 50/200\n",
      "260/260 - 5s - loss: 0.0467 - accuracy: 0.9866\n",
      "Epoch 51/200\n",
      "260/260 - 5s - loss: 0.0452 - accuracy: 0.9870\n",
      "Epoch 52/200\n",
      "260/260 - 6s - loss: 0.0431 - accuracy: 0.9872\n",
      "Epoch 53/200\n",
      "260/260 - 6s - loss: 0.0406 - accuracy: 0.9888\n",
      "Epoch 54/200\n",
      "260/260 - 5s - loss: 0.0445 - accuracy: 0.9878\n",
      "Epoch 55/200\n",
      "260/260 - 4s - loss: 0.0438 - accuracy: 0.9880\n",
      "Epoch 56/200\n",
      "260/260 - 4s - loss: 0.0387 - accuracy: 0.9895\n",
      "Epoch 57/200\n",
      "260/260 - 4s - loss: 0.0360 - accuracy: 0.9897\n",
      "Epoch 58/200\n",
      "260/260 - 4s - loss: 0.0394 - accuracy: 0.9894\n",
      "Epoch 59/200\n",
      "260/260 - 5s - loss: 0.0368 - accuracy: 0.9899\n",
      "Epoch 60/200\n",
      "260/260 - 5s - loss: 0.0358 - accuracy: 0.9906\n",
      "Epoch 61/200\n",
      "260/260 - 6s - loss: 0.0326 - accuracy: 0.9909\n",
      "Epoch 62/200\n",
      "260/260 - 6s - loss: 0.0365 - accuracy: 0.9904\n",
      "Epoch 63/200\n",
      "260/260 - 6s - loss: 0.0337 - accuracy: 0.9912\n",
      "Epoch 64/200\n",
      "260/260 - 6s - loss: 0.0340 - accuracy: 0.9914\n",
      "Epoch 65/200\n",
      "260/260 - 5s - loss: 0.0308 - accuracy: 0.9920\n",
      "Epoch 66/200\n",
      "260/260 - 5s - loss: 0.0332 - accuracy: 0.9912\n",
      "Epoch 67/200\n",
      "260/260 - 4s - loss: 0.0294 - accuracy: 0.9922\n",
      "Epoch 68/200\n",
      "260/260 - 4s - loss: 0.0293 - accuracy: 0.9929\n",
      "Epoch 69/200\n",
      "260/260 - 4s - loss: 0.0281 - accuracy: 0.9932\n",
      "Epoch 70/200\n",
      "260/260 - 4s - loss: 0.0283 - accuracy: 0.9928\n",
      "Epoch 71/200\n",
      "260/260 - 4s - loss: 0.0255 - accuracy: 0.9943\n",
      "Epoch 72/200\n",
      "260/260 - 4s - loss: 0.0311 - accuracy: 0.9926\n",
      "Epoch 73/200\n",
      "260/260 - 4s - loss: 0.0310 - accuracy: 0.9922\n",
      "Epoch 74/200\n",
      "260/260 - 5s - loss: 0.0272 - accuracy: 0.9936\n",
      "Epoch 75/200\n",
      "260/260 - 5s - loss: 0.0289 - accuracy: 0.9930\n",
      "Epoch 76/200\n",
      "260/260 - 5s - loss: 0.0273 - accuracy: 0.9933\n",
      "Epoch 77/200\n",
      "260/260 - 4s - loss: 0.0289 - accuracy: 0.9927\n",
      "Epoch 78/200\n",
      "260/260 - 4s - loss: 0.0241 - accuracy: 0.9947\n",
      "Epoch 79/200\n",
      "260/260 - 4s - loss: 0.0255 - accuracy: 0.9933\n",
      "Epoch 80/200\n",
      "260/260 - 4s - loss: 0.0281 - accuracy: 0.9938\n",
      "Epoch 81/200\n",
      "260/260 - 4s - loss: 0.0240 - accuracy: 0.9946\n",
      "Epoch 82/200\n",
      "260/260 - 4s - loss: 0.0260 - accuracy: 0.9934\n",
      "Epoch 83/200\n",
      "260/260 - 5s - loss: 0.0247 - accuracy: 0.9940\n",
      "Epoch 84/200\n",
      "260/260 - 4s - loss: 0.0252 - accuracy: 0.9942\n",
      "Epoch 85/200\n",
      "260/260 - 5s - loss: 0.0249 - accuracy: 0.9940\n",
      "Epoch 86/200\n",
      "260/260 - 4s - loss: 0.0253 - accuracy: 0.9943\n",
      "Epoch 87/200\n",
      "260/260 - 4s - loss: 0.0241 - accuracy: 0.9942\n",
      "Epoch 88/200\n",
      "260/260 - 4s - loss: 0.0234 - accuracy: 0.9949\n",
      "Epoch 89/200\n",
      "260/260 - 4s - loss: 0.0260 - accuracy: 0.9941\n",
      "Epoch 90/200\n",
      "260/260 - 5s - loss: 0.0244 - accuracy: 0.9950\n",
      "Epoch 91/200\n",
      "260/260 - 5s - loss: 0.0243 - accuracy: 0.9944\n",
      "Epoch 92/200\n",
      "260/260 - 5s - loss: 0.0211 - accuracy: 0.9953\n",
      "Epoch 93/200\n",
      "260/260 - 5s - loss: 0.0236 - accuracy: 0.9948\n",
      "Epoch 94/200\n",
      "260/260 - 5s - loss: 0.0216 - accuracy: 0.9955\n",
      "Epoch 95/200\n",
      "260/260 - 6s - loss: 0.0234 - accuracy: 0.9954\n",
      "Epoch 96/200\n",
      "260/260 - 6s - loss: 0.0228 - accuracy: 0.9952\n",
      "Epoch 97/200\n",
      "260/260 - 5s - loss: 0.0226 - accuracy: 0.9952\n",
      "Epoch 98/200\n",
      "260/260 - 4s - loss: 0.0231 - accuracy: 0.9949\n",
      "Epoch 99/200\n",
      "260/260 - 4s - loss: 0.0225 - accuracy: 0.9952\n",
      "Epoch 100/200\n",
      "260/260 - 5s - loss: 0.0214 - accuracy: 0.9960\n",
      "Epoch 101/200\n",
      "260/260 - 5s - loss: 0.0215 - accuracy: 0.9954\n",
      "Epoch 102/200\n",
      "260/260 - 4s - loss: 0.0211 - accuracy: 0.9952\n",
      "Epoch 103/200\n",
      "260/260 - 5s - loss: 0.0241 - accuracy: 0.9948\n",
      "Epoch 104/200\n",
      "260/260 - 4s - loss: 0.0245 - accuracy: 0.9953\n",
      "Epoch 105/200\n",
      "260/260 - 5s - loss: 0.0232 - accuracy: 0.9951\n",
      "Epoch 106/200\n",
      "260/260 - 5s - loss: 0.0242 - accuracy: 0.9952\n",
      "Epoch 107/200\n",
      "260/260 - 5s - loss: 0.0234 - accuracy: 0.9949\n",
      "Epoch 108/200\n",
      "260/260 - 5s - loss: 0.0216 - accuracy: 0.9956\n",
      "Epoch 109/200\n",
      "260/260 - 5s - loss: 0.0246 - accuracy: 0.9947\n",
      "Epoch 110/200\n",
      "260/260 - 6s - loss: 0.0228 - accuracy: 0.9954\n",
      "Epoch 111/200\n",
      "260/260 - 6s - loss: 0.0235 - accuracy: 0.9953\n",
      "Epoch 112/200\n",
      "260/260 - 5s - loss: 0.0210 - accuracy: 0.9958\n",
      "Epoch 113/200\n",
      "260/260 - 6s - loss: 0.0240 - accuracy: 0.9947\n",
      "Epoch 114/200\n",
      "260/260 - 5s - loss: 0.0219 - accuracy: 0.9954\n",
      "Epoch 115/200\n",
      "260/260 - 6s - loss: 0.0223 - accuracy: 0.9954\n",
      "Epoch 116/200\n",
      "260/260 - 6s - loss: 0.0247 - accuracy: 0.9947\n",
      "Epoch 117/200\n",
      "260/260 - 5s - loss: 0.0197 - accuracy: 0.9961\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 - 5s - loss: 0.0250 - accuracy: 0.9946\n",
      "Epoch 119/200\n",
      "260/260 - 5s - loss: 0.0247 - accuracy: 0.9952\n",
      "Epoch 120/200\n",
      "260/260 - 4s - loss: 0.0187 - accuracy: 0.9962\n",
      "Epoch 121/200\n",
      "260/260 - 4s - loss: 0.0227 - accuracy: 0.9954\n",
      "Epoch 122/200\n",
      "260/260 - 4s - loss: 0.0230 - accuracy: 0.9953\n",
      "Epoch 123/200\n",
      "260/260 - 4s - loss: 0.0235 - accuracy: 0.9950\n",
      "Epoch 124/200\n",
      "260/260 - 4s - loss: 0.0229 - accuracy: 0.9952\n",
      "Epoch 125/200\n",
      "260/260 - 4s - loss: 0.0218 - accuracy: 0.9955\n",
      "Epoch 126/200\n",
      "260/260 - 4s - loss: 0.0220 - accuracy: 0.9959\n",
      "Epoch 127/200\n",
      "260/260 - 4s - loss: 0.0257 - accuracy: 0.9949\n",
      "Epoch 128/200\n",
      "260/260 - 4s - loss: 0.0226 - accuracy: 0.9956\n",
      "Epoch 129/200\n",
      "260/260 - 4s - loss: 0.0240 - accuracy: 0.9954\n",
      "Epoch 130/200\n",
      "260/260 - 4s - loss: 0.0201 - accuracy: 0.9966\n",
      "Epoch 131/200\n",
      "260/260 - 4s - loss: 0.0251 - accuracy: 0.9955\n",
      "Epoch 132/200\n",
      "260/260 - 5s - loss: 0.0225 - accuracy: 0.9957\n",
      "Epoch 133/200\n",
      "260/260 - 5s - loss: 0.0229 - accuracy: 0.9956\n",
      "Epoch 134/200\n",
      "260/260 - 4s - loss: 0.0210 - accuracy: 0.9959\n",
      "Epoch 135/200\n",
      "260/260 - 4s - loss: 0.0231 - accuracy: 0.9958\n",
      "Epoch 136/200\n",
      "260/260 - 4s - loss: 0.0213 - accuracy: 0.9952\n",
      "Epoch 137/200\n",
      "260/260 - 4s - loss: 0.0207 - accuracy: 0.9958\n",
      "Epoch 138/200\n",
      "260/260 - 5s - loss: 0.0200 - accuracy: 0.9965\n",
      "Epoch 139/200\n",
      "260/260 - 5s - loss: 0.0212 - accuracy: 0.9960\n",
      "Epoch 140/200\n",
      "260/260 - 5s - loss: 0.0204 - accuracy: 0.9960\n",
      "Epoch 141/200\n",
      "260/260 - 4s - loss: 0.0234 - accuracy: 0.9952\n",
      "Epoch 142/200\n",
      "260/260 - 4s - loss: 0.0213 - accuracy: 0.9963\n",
      "Epoch 143/200\n",
      "260/260 - 4s - loss: 0.0222 - accuracy: 0.9954\n",
      "Epoch 144/200\n",
      "260/260 - 4s - loss: 0.0219 - accuracy: 0.9960\n",
      "Epoch 145/200\n",
      "260/260 - 4s - loss: 0.0233 - accuracy: 0.9957\n",
      "Epoch 146/200\n",
      "260/260 - 4s - loss: 0.0219 - accuracy: 0.9957\n",
      "Epoch 147/200\n",
      "260/260 - 4s - loss: 0.0197 - accuracy: 0.9963\n",
      "Epoch 148/200\n",
      "260/260 - 5s - loss: 0.0200 - accuracy: 0.9960\n",
      "Epoch 149/200\n",
      "260/260 - 4s - loss: 0.0171 - accuracy: 0.9968\n",
      "Epoch 150/200\n",
      "260/260 - 4s - loss: 0.0189 - accuracy: 0.9963\n",
      "Epoch 151/200\n",
      "260/260 - 5s - loss: 0.0198 - accuracy: 0.9963\n",
      "Epoch 152/200\n",
      "260/260 - 5s - loss: 0.0213 - accuracy: 0.9959\n",
      "Epoch 153/200\n",
      "260/260 - 5s - loss: 0.0183 - accuracy: 0.9967\n",
      "Epoch 154/200\n",
      "260/260 - 6s - loss: 0.0192 - accuracy: 0.9968\n",
      "Epoch 155/200\n",
      "260/260 - 10s - loss: 0.0193 - accuracy: 0.9966\n",
      "Epoch 156/200\n",
      "260/260 - 7s - loss: 0.0173 - accuracy: 0.9968\n",
      "Epoch 157/200\n",
      "260/260 - 9s - loss: 0.0191 - accuracy: 0.9964\n",
      "Epoch 158/200\n",
      "260/260 - 7s - loss: 0.0205 - accuracy: 0.9957\n",
      "Epoch 159/200\n",
      "260/260 - 5s - loss: 0.0191 - accuracy: 0.9964\n",
      "Epoch 160/200\n",
      "260/260 - 5s - loss: 0.0176 - accuracy: 0.9969\n",
      "Epoch 161/200\n",
      "260/260 - 5s - loss: 0.0208 - accuracy: 0.9961\n",
      "Epoch 162/200\n",
      "260/260 - 5s - loss: 0.0171 - accuracy: 0.9971\n",
      "Epoch 163/200\n",
      "260/260 - 5s - loss: 0.0203 - accuracy: 0.9963\n",
      "Epoch 164/200\n",
      "260/260 - 5s - loss: 0.0180 - accuracy: 0.9970\n",
      "Epoch 165/200\n",
      "260/260 - 6s - loss: 0.0207 - accuracy: 0.9962\n",
      "Epoch 166/200\n",
      "260/260 - 10s - loss: 0.0200 - accuracy: 0.9965\n",
      "Epoch 167/200\n",
      "260/260 - 7s - loss: 0.0188 - accuracy: 0.9966\n",
      "Epoch 168/200\n",
      "260/260 - 6s - loss: 0.0214 - accuracy: 0.9960\n",
      "Epoch 169/200\n",
      "260/260 - 6s - loss: 0.0215 - accuracy: 0.9955\n",
      "Epoch 170/200\n",
      "260/260 - 8s - loss: 0.0184 - accuracy: 0.9968\n",
      "Epoch 171/200\n",
      "260/260 - 11s - loss: 0.0211 - accuracy: 0.9963\n",
      "Epoch 172/200\n",
      "260/260 - 7s - loss: 0.0199 - accuracy: 0.9965\n",
      "Epoch 173/200\n",
      "260/260 - 6s - loss: 0.0163 - accuracy: 0.9968\n",
      "Epoch 174/200\n",
      "260/260 - 5s - loss: 0.0173 - accuracy: 0.9968\n",
      "Epoch 175/200\n",
      "260/260 - 6s - loss: 0.0205 - accuracy: 0.9965\n",
      "Epoch 176/200\n",
      "260/260 - 5s - loss: 0.0181 - accuracy: 0.9969\n",
      "Epoch 177/200\n",
      "260/260 - 5s - loss: 0.0186 - accuracy: 0.9965\n",
      "Epoch 178/200\n",
      "260/260 - 7s - loss: 0.0176 - accuracy: 0.9968\n",
      "Epoch 179/200\n",
      "260/260 - 7s - loss: 0.0179 - accuracy: 0.9968\n",
      "Epoch 180/200\n",
      "260/260 - 8s - loss: 0.0173 - accuracy: 0.9968\n",
      "Epoch 181/200\n",
      "260/260 - 7s - loss: 0.0179 - accuracy: 0.9972\n",
      "Epoch 182/200\n",
      "260/260 - 5s - loss: 0.0202 - accuracy: 0.9965\n",
      "Epoch 183/200\n",
      "260/260 - 5s - loss: 0.0181 - accuracy: 0.9965\n",
      "Epoch 184/200\n",
      "260/260 - 5s - loss: 0.0192 - accuracy: 0.9965\n",
      "Epoch 185/200\n",
      "260/260 - 4s - loss: 0.0186 - accuracy: 0.9965\n",
      "Epoch 186/200\n",
      "260/260 - 4s - loss: 0.0186 - accuracy: 0.9967\n",
      "Epoch 187/200\n",
      "260/260 - 5s - loss: 0.0179 - accuracy: 0.9966\n",
      "Epoch 188/200\n",
      "260/260 - 5s - loss: 0.0169 - accuracy: 0.9971\n",
      "Epoch 189/200\n",
      "260/260 - 4s - loss: 0.0180 - accuracy: 0.9969\n",
      "Epoch 190/200\n",
      "260/260 - 6s - loss: 0.0183 - accuracy: 0.9965\n",
      "Epoch 191/200\n",
      "260/260 - 6s - loss: 0.0216 - accuracy: 0.9961\n",
      "Epoch 192/200\n",
      "260/260 - 7s - loss: 0.0202 - accuracy: 0.9960\n",
      "Epoch 193/200\n",
      "260/260 - 6s - loss: 0.0173 - accuracy: 0.9966\n",
      "Epoch 194/200\n",
      "260/260 - 7s - loss: 0.0203 - accuracy: 0.9963\n",
      "Epoch 195/200\n",
      "260/260 - 6s - loss: 0.0175 - accuracy: 0.9969\n",
      "Epoch 196/200\n",
      "260/260 - 5s - loss: 0.0193 - accuracy: 0.9966\n",
      "Epoch 197/200\n",
      "260/260 - 6s - loss: 0.0194 - accuracy: 0.9966\n",
      "Epoch 198/200\n",
      "260/260 - 6s - loss: 0.0179 - accuracy: 0.9969\n",
      "Epoch 199/200\n",
      "260/260 - 5s - loss: 0.0223 - accuracy: 0.9960\n",
      "Epoch 200/200\n",
      "260/260 - 5s - loss: 0.0190 - accuracy: 0.9964\n",
      "128/128 - 1s - loss: 0.6560 - accuracy: 0.8814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6560125350952148, 0.8814118504524231]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(keras.Input(shape=(x_train.shape[1],1)))\n",
    "\n",
    "model.add(keras.Input(shape=(1,x_train.shape[2])))\n",
    "\n",
    "model.add(layers.Bidirectional(layers.LSTM(256, return_sequences=True, activation=\"relu\")))\n",
    "\n",
    "model.add(layers.LSTM(128, name=\"lstm_layer2\"))\n",
    "\n",
    "# model.add(LSTM(512, activation='exponential'))\n",
    "model.add(layers.Dense(64, activation='exponential'))\n",
    "\n",
    "model.add(layers.Dense(30,activation='hard_sigmoid'))\n",
    "\n",
    "model.add(layers.Dense(10,activation='tanh'))\n",
    "\n",
    "# model.add(layers.Dense(16,activation='hard_sigmoid'))\n",
    "\n",
    "# model.add(LSTM(64, activation='exponential'))\n",
    "# model.add(layers.Dense(10,activation='hard_sigmoid'))\n",
    "# model.add(layers.Dense(10,activation='tanh'))\n",
    "\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=200, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T15:33:41.963536Z",
     "start_time": "2022-05-24T15:33:14.570Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# # model.add(LSTM(100, activation='tanh', return_sequences=True, input_shape=(1, x_train.shape[1])))\n",
    "# model.add(layers.Bidirectional(layers.LSTM(500, return_sequences=True, activation=\"tanh\",input_shape=(1, x_train.shape[2]))))\n",
    "# model.add(LSTM(300, activation='tanh'))\n",
    "# model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(optimizer=\"rmsprop\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(x_train,y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T17:06:50.992686Z",
     "start_time": "2022-05-24T17:06:48.312702Z"
    }
   },
   "outputs": [],
   "source": [
    "o=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T17:06:58.112658Z",
     "start_time": "2022-05-24T17:06:58.070658Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_prep=[]\n",
    "for i in range(len(o)):\n",
    "    Y_prep.append(round(o[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T17:07:02.184659Z",
     "start_time": "2022-05-24T17:07:02.111661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6441  405]\n",
      " [ 566  776]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,Y_prep)\n",
    "print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idiomatic classification accuracy! :  0.9408413672217353\n"
     ]
    }
   ],
   "source": [
    "print(\"Idiomatic classification accuracy! : \",(6441 / (6441+405)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Literal classification accuracy! :  0.5782414307004471\n"
     ]
    }
   ],
   "source": [
    "print(\"Literal classification accuracy! : \",(776 / (776+566)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall classification accuracy! :  0.8814118221787982\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall classification accuracy! : \",((776+6441) / (6441+405+566+776)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
