{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:21.556125Z",
     "start_time": "2022-04-30T20:26:21.551138Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import ast\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:00.944581Z",
     "start_time": "2022-04-30T20:25:55.956110Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('legit_ones_5l_vectors.xlsx')\n",
    "# excel table of vectors only for the legitimate idiomatic expressions. \n",
    "#Where there is an exact match of the idiom in the contexts column and idiom column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:00.976498Z",
     "start_time": "2022-04-30T20:26:00.946575Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "df['label']=encoder.fit_transform(df['label'])\n",
    "#Converting the label i and l denoting idom and literal, to zero and 1 for ease of classificstion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:03.098891Z",
     "start_time": "2022-04-30T20:26:00.979487Z"
    }
   },
   "outputs": [],
   "source": [
    "# max lenth of is 45 for idioms\n",
    "r=[]\n",
    "for i in range(df.shape[0]):\n",
    "    x = ast.literal_eval(df['all_idiom_5l_each_word'][i])\n",
    "    r.append(x)\n",
    "#Converting string list into list, wrong type would cause an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:03.238446Z",
     "start_time": "2022-04-30T20:26:03.100812Z"
    }
   },
   "outputs": [],
   "source": [
    "for j in range(len(r)):\n",
    "    for i in range(45-len(r[j])):\n",
    "        r[j].append(0)\n",
    "#Addition of zeros after the 45-th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:03.551911Z",
     "start_time": "2022-04-30T20:26:03.239443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.706041</td>\n",
       "      <td>-2.400280</td>\n",
       "      <td>1.441445</td>\n",
       "      <td>-1.572476</td>\n",
       "      <td>3.178705</td>\n",
       "      <td>-0.989343</td>\n",
       "      <td>-2.965439</td>\n",
       "      <td>-1.656484</td>\n",
       "      <td>-0.818308</td>\n",
       "      <td>2.228827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.911975</td>\n",
       "      <td>0.466270</td>\n",
       "      <td>-0.744243</td>\n",
       "      <td>-1.081924</td>\n",
       "      <td>-2.690621</td>\n",
       "      <td>-1.982522</td>\n",
       "      <td>-1.727190</td>\n",
       "      <td>-2.760475</td>\n",
       "      <td>-1.732051</td>\n",
       "      <td>-0.339831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.264573</td>\n",
       "      <td>0.961804</td>\n",
       "      <td>3.210402</td>\n",
       "      <td>-0.762324</td>\n",
       "      <td>0.473270</td>\n",
       "      <td>-2.267075</td>\n",
       "      <td>-0.246786</td>\n",
       "      <td>2.582364</td>\n",
       "      <td>0.359696</td>\n",
       "      <td>0.347087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.912891</td>\n",
       "      <td>0.240082</td>\n",
       "      <td>2.398815</td>\n",
       "      <td>0.254071</td>\n",
       "      <td>0.138524</td>\n",
       "      <td>1.709964</td>\n",
       "      <td>0.659743</td>\n",
       "      <td>0.193390</td>\n",
       "      <td>0.474542</td>\n",
       "      <td>2.163204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.461462</td>\n",
       "      <td>-0.827581</td>\n",
       "      <td>-1.058371</td>\n",
       "      <td>-2.533165</td>\n",
       "      <td>2.605412</td>\n",
       "      <td>-2.262347</td>\n",
       "      <td>5.604730</td>\n",
       "      <td>-0.617172</td>\n",
       "      <td>0.278911</td>\n",
       "      <td>0.153157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24805</th>\n",
       "      <td>-1.573374</td>\n",
       "      <td>4.653001</td>\n",
       "      <td>1.094262</td>\n",
       "      <td>-2.634780</td>\n",
       "      <td>2.059686</td>\n",
       "      <td>0.240416</td>\n",
       "      <td>0.289104</td>\n",
       "      <td>-0.246852</td>\n",
       "      <td>-0.731543</td>\n",
       "      <td>0.361849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24806</th>\n",
       "      <td>0.197703</td>\n",
       "      <td>2.343588</td>\n",
       "      <td>2.757625</td>\n",
       "      <td>-0.619617</td>\n",
       "      <td>1.132591</td>\n",
       "      <td>0.914919</td>\n",
       "      <td>0.469362</td>\n",
       "      <td>3.042929</td>\n",
       "      <td>-0.427493</td>\n",
       "      <td>3.312955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24807</th>\n",
       "      <td>-2.161072</td>\n",
       "      <td>2.054279</td>\n",
       "      <td>2.774971</td>\n",
       "      <td>1.189215</td>\n",
       "      <td>4.888242</td>\n",
       "      <td>-0.735887</td>\n",
       "      <td>1.086011</td>\n",
       "      <td>2.906706</td>\n",
       "      <td>0.553608</td>\n",
       "      <td>2.586283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24808</th>\n",
       "      <td>4.936450</td>\n",
       "      <td>7.411347</td>\n",
       "      <td>1.970084</td>\n",
       "      <td>-2.220847</td>\n",
       "      <td>-1.292620</td>\n",
       "      <td>0.453957</td>\n",
       "      <td>4.809259</td>\n",
       "      <td>2.020978</td>\n",
       "      <td>-3.288856</td>\n",
       "      <td>-2.603212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24809</th>\n",
       "      <td>1.145146</td>\n",
       "      <td>-0.745880</td>\n",
       "      <td>0.171952</td>\n",
       "      <td>-1.818744</td>\n",
       "      <td>3.333541</td>\n",
       "      <td>-4.011673</td>\n",
       "      <td>1.990396</td>\n",
       "      <td>-0.458345</td>\n",
       "      <td>-3.002555</td>\n",
       "      <td>5.025704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24810 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.706041 -2.400280  1.441445 -1.572476  3.178705 -0.989343 -2.965439   \n",
       "1     -2.911975  0.466270 -0.744243 -1.081924 -2.690621 -1.982522 -1.727190   \n",
       "2     -1.264573  0.961804  3.210402 -0.762324  0.473270 -2.267075 -0.246786   \n",
       "3      3.912891  0.240082  2.398815  0.254071  0.138524  1.709964  0.659743   \n",
       "4      0.461462 -0.827581 -1.058371 -2.533165  2.605412 -2.262347  5.604730   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24805 -1.573374  4.653001  1.094262 -2.634780  2.059686  0.240416  0.289104   \n",
       "24806  0.197703  2.343588  2.757625 -0.619617  1.132591  0.914919  0.469362   \n",
       "24807 -2.161072  2.054279  2.774971  1.189215  4.888242 -0.735887  1.086011   \n",
       "24808  4.936450  7.411347  1.970084 -2.220847 -1.292620  0.453957  4.809259   \n",
       "24809  1.145146 -0.745880  0.171952 -1.818744  3.333541 -4.011673  1.990396   \n",
       "\n",
       "              7         8         9  ...   36   37   38   39   40   41   42  \\\n",
       "0     -1.656484 -0.818308  2.228827  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1     -2.760475 -1.732051 -0.339831  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      2.582364  0.359696  0.347087  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      0.193390  0.474542  2.163204  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     -0.617172  0.278911  0.153157  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "24805 -0.246852 -0.731543  0.361849  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "24806  3.042929 -0.427493  3.312955  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "24807  2.906706  0.553608  2.586283  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "24808  2.020978 -3.288856 -2.603212  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "24809 -0.458345 -3.002555  5.025704  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        43   44  y  \n",
       "0      0.0  0.0  0  \n",
       "1      0.0  0.0  0  \n",
       "2      0.0  0.0  0  \n",
       "3      0.0  0.0  0  \n",
       "4      0.0  0.0  0  \n",
       "...    ...  ... ..  \n",
       "24805  0.0  0.0  0  \n",
       "24806  0.0  0.0  1  \n",
       "24807  0.0  0.0  0  \n",
       "24808  0.0  0.0  0  \n",
       "24809  0.0  0.0  0  \n",
       "\n",
       "[24810 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=pd.concat([pd.DataFrame(r),pd.DataFrame(list(df['label']),columns=['y'])],axis=1)\n",
    "data1\n",
    "#Displaying the vector data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:03.567830Z",
     "start_time": "2022-04-30T20:26:03.554864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16742, 46)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_idiom=data1[(data1['y']==0)&(data1.index<20000)].reset_index(drop=True)\n",
    "# train_idiom.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:03.583789Z",
     "start_time": "2022-04-30T20:26:03.569825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16742, 46)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_literal=data1[(data1['y']==1)&(data1.index<20000)].reset_index(drop=True)\n",
    "# train_literal_bias=pd.DataFrame()\n",
    "# train_literal_bias=pd.concat([train_literal_bias,train_literal,train_literal,train_literal,train_literal,train_literal,train_literal[0:452]],axis=0)\n",
    "# train_literal_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:03.631660Z",
     "start_time": "2022-04-30T20:26:03.585783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200794</td>\n",
       "      <td>1.746465</td>\n",
       "      <td>-2.469869</td>\n",
       "      <td>-2.413901</td>\n",
       "      <td>3.175566</td>\n",
       "      <td>2.754219</td>\n",
       "      <td>3.479995</td>\n",
       "      <td>0.845903</td>\n",
       "      <td>-2.629498</td>\n",
       "      <td>6.356821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.471947</td>\n",
       "      <td>0.251455</td>\n",
       "      <td>-0.852516</td>\n",
       "      <td>0.875013</td>\n",
       "      <td>0.907998</td>\n",
       "      <td>-5.074784</td>\n",
       "      <td>-1.981690</td>\n",
       "      <td>-1.358121</td>\n",
       "      <td>1.145342</td>\n",
       "      <td>2.465438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.398004</td>\n",
       "      <td>-1.787525</td>\n",
       "      <td>0.093280</td>\n",
       "      <td>-1.910716</td>\n",
       "      <td>3.612620</td>\n",
       "      <td>-2.922696</td>\n",
       "      <td>-0.794799</td>\n",
       "      <td>-0.683657</td>\n",
       "      <td>2.075389</td>\n",
       "      <td>1.013283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.163574</td>\n",
       "      <td>-2.277607</td>\n",
       "      <td>0.512381</td>\n",
       "      <td>-4.007491</td>\n",
       "      <td>-0.503701</td>\n",
       "      <td>-2.844902</td>\n",
       "      <td>-4.045784</td>\n",
       "      <td>-0.653298</td>\n",
       "      <td>-2.134147</td>\n",
       "      <td>0.967743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.647244</td>\n",
       "      <td>1.636005</td>\n",
       "      <td>-0.747913</td>\n",
       "      <td>-1.711509</td>\n",
       "      <td>4.521041</td>\n",
       "      <td>0.742066</td>\n",
       "      <td>4.090480</td>\n",
       "      <td>-0.664268</td>\n",
       "      <td>-1.796380</td>\n",
       "      <td>5.209273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>-2.845213</td>\n",
       "      <td>3.246986</td>\n",
       "      <td>-0.339011</td>\n",
       "      <td>5.081264</td>\n",
       "      <td>2.669884</td>\n",
       "      <td>-4.743480</td>\n",
       "      <td>4.011475</td>\n",
       "      <td>-1.459684</td>\n",
       "      <td>6.556819</td>\n",
       "      <td>1.923460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>-1.996757</td>\n",
       "      <td>0.283110</td>\n",
       "      <td>-1.624118</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.498333</td>\n",
       "      <td>-0.903049</td>\n",
       "      <td>2.904166</td>\n",
       "      <td>-0.832911</td>\n",
       "      <td>4.955476</td>\n",
       "      <td>0.796886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>-1.657352</td>\n",
       "      <td>2.667484</td>\n",
       "      <td>2.989386</td>\n",
       "      <td>-2.029863</td>\n",
       "      <td>2.197638</td>\n",
       "      <td>-0.436760</td>\n",
       "      <td>-0.626940</td>\n",
       "      <td>3.460732</td>\n",
       "      <td>-0.748058</td>\n",
       "      <td>4.563299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>-1.194216</td>\n",
       "      <td>2.536058</td>\n",
       "      <td>1.035588</td>\n",
       "      <td>0.031019</td>\n",
       "      <td>-0.470849</td>\n",
       "      <td>-2.807090</td>\n",
       "      <td>1.284870</td>\n",
       "      <td>-0.393757</td>\n",
       "      <td>0.377447</td>\n",
       "      <td>-0.401311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-1.105914</td>\n",
       "      <td>1.593325</td>\n",
       "      <td>3.017853</td>\n",
       "      <td>-1.951643</td>\n",
       "      <td>-1.316843</td>\n",
       "      <td>-0.715635</td>\n",
       "      <td>-0.531083</td>\n",
       "      <td>-0.207648</td>\n",
       "      <td>-0.779627</td>\n",
       "      <td>0.666357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.200794  1.746465 -2.469869 -2.413901  3.175566  2.754219  3.479995   \n",
       "1   -4.471947  0.251455 -0.852516  0.875013  0.907998 -5.074784 -1.981690   \n",
       "2   -0.398004 -1.787525  0.093280 -1.910716  3.612620 -2.922696 -0.794799   \n",
       "3   -3.163574 -2.277607  0.512381 -4.007491 -0.503701 -2.844902 -4.045784   \n",
       "4   -1.647244  1.636005 -0.747913 -1.711509  4.521041  0.742066  4.090480   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "447 -2.845213  3.246986 -0.339011  5.081264  2.669884 -4.743480  4.011475   \n",
       "448 -1.996757  0.283110 -1.624118  0.087100  0.498333 -0.903049  2.904166   \n",
       "449 -1.657352  2.667484  2.989386 -2.029863  2.197638 -0.436760 -0.626940   \n",
       "450 -1.194216  2.536058  1.035588  0.031019 -0.470849 -2.807090  1.284870   \n",
       "451 -1.105914  1.593325  3.017853 -1.951643 -1.316843 -0.715635 -0.531083   \n",
       "\n",
       "            7         8         9  ...   36   37   38   39   40   41   42  \\\n",
       "0    0.845903 -2.629498  6.356821  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1   -1.358121  1.145342  2.465438  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2   -0.683657  2.075389  1.013283  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3   -0.653298 -2.134147  0.967743  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4   -0.664268 -1.796380  5.209273  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "..        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "447 -1.459684  6.556819  1.923460  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "448 -0.832911  4.955476  0.796886  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "449  3.460732 -0.748058  4.563299  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "450 -0.393757  0.377447 -0.401311  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "451 -0.207648 -0.779627  0.666357  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      43   44  y  \n",
       "0    0.0  0.0  1  \n",
       "1    0.0  0.0  1  \n",
       "2    0.0  0.0  1  \n",
       "3    0.0  0.0  1  \n",
       "4    0.0  0.0  1  \n",
       "..   ...  ... ..  \n",
       "447  0.0  0.0  1  \n",
       "448  0.0  0.0  1  \n",
       "449  0.0  0.0  1  \n",
       "450  0.0  0.0  1  \n",
       "451  0.0  0.0  1  \n",
       "\n",
       "[452 rows x 46 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_literal[0:452]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:03.647617Z",
     "start_time": "2022-04-30T20:26:03.634657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16742-3258*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:51:29.111495Z",
     "start_time": "2022-04-30T20:51:29.037689Z"
    }
   },
   "outputs": [],
   "source": [
    "train_idiom=data1[(data1['y']==0)&(data1.index<20000)].reset_index(drop=True)[0:3258]\n",
    "train_literal=data1[(data1['y']==1)&(data1.index<20000)].reset_index(drop=True)[0:3258]\n",
    "train=pd.concat([train_idiom,train_literal],axis=0).reset_index(drop=True)\n",
    "train= train.sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "test_literal=data1[(data1['y']==1)&(data1.index>20000)].reset_index(drop=True)\n",
    "test_idiom=data1[(data1['y']==0)&(data1.index>20000)].reset_index(drop=True)[0:769]\n",
    "test=pd.concat([test_idiom,test_literal],axis=0).reset_index(drop=True)\n",
    "test=test.sample(frac = 1).reset_index(drop=True)\n",
    "# Testing and training data split with a ratio of 50:50 for idiom and literal labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.180118</td>\n",
       "      <td>5.013660</td>\n",
       "      <td>2.860423</td>\n",
       "      <td>-2.865401</td>\n",
       "      <td>-0.028288</td>\n",
       "      <td>-3.619290</td>\n",
       "      <td>0.292545</td>\n",
       "      <td>-0.524740</td>\n",
       "      <td>-2.217012</td>\n",
       "      <td>-1.054117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.472042</td>\n",
       "      <td>3.915963</td>\n",
       "      <td>2.068798</td>\n",
       "      <td>-5.190753</td>\n",
       "      <td>0.329500</td>\n",
       "      <td>-3.115555</td>\n",
       "      <td>4.373549</td>\n",
       "      <td>2.080570</td>\n",
       "      <td>-5.787605</td>\n",
       "      <td>-2.315120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.667763</td>\n",
       "      <td>4.113233</td>\n",
       "      <td>0.487150</td>\n",
       "      <td>0.271637</td>\n",
       "      <td>3.015929</td>\n",
       "      <td>0.319480</td>\n",
       "      <td>3.013111</td>\n",
       "      <td>0.576483</td>\n",
       "      <td>0.880548</td>\n",
       "      <td>-2.119671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.306537</td>\n",
       "      <td>2.147649</td>\n",
       "      <td>1.115982</td>\n",
       "      <td>-2.374482</td>\n",
       "      <td>-2.725207</td>\n",
       "      <td>-1.637658</td>\n",
       "      <td>1.236538</td>\n",
       "      <td>-0.551501</td>\n",
       "      <td>-3.421391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.884463</td>\n",
       "      <td>-4.142449</td>\n",
       "      <td>1.544765</td>\n",
       "      <td>-2.158188</td>\n",
       "      <td>-2.536783</td>\n",
       "      <td>-2.528181</td>\n",
       "      <td>-2.324859</td>\n",
       "      <td>3.421148</td>\n",
       "      <td>-1.575434</td>\n",
       "      <td>-0.027419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-2.442063</td>\n",
       "      <td>4.145002</td>\n",
       "      <td>0.046409</td>\n",
       "      <td>-1.669268</td>\n",
       "      <td>-0.617231</td>\n",
       "      <td>-3.632627</td>\n",
       "      <td>-1.634848</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>-2.828122</td>\n",
       "      <td>0.877553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.669439</td>\n",
       "      <td>-0.016730</td>\n",
       "      <td>0.260739</td>\n",
       "      <td>-1.106865</td>\n",
       "      <td>-0.652408</td>\n",
       "      <td>-2.188516</td>\n",
       "      <td>-0.368060</td>\n",
       "      <td>3.067914</td>\n",
       "      <td>-0.264205</td>\n",
       "      <td>-2.123014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.013926</td>\n",
       "      <td>3.661481</td>\n",
       "      <td>1.313774</td>\n",
       "      <td>-0.589418</td>\n",
       "      <td>-2.415130</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>3.171532</td>\n",
       "      <td>-1.222912</td>\n",
       "      <td>3.141354</td>\n",
       "      <td>-1.771899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.011871</td>\n",
       "      <td>0.952472</td>\n",
       "      <td>-1.284622</td>\n",
       "      <td>0.115353</td>\n",
       "      <td>0.384778</td>\n",
       "      <td>-0.522033</td>\n",
       "      <td>2.936195</td>\n",
       "      <td>1.016842</td>\n",
       "      <td>-2.286952</td>\n",
       "      <td>-1.036577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>1.339266</td>\n",
       "      <td>-2.163447</td>\n",
       "      <td>1.005169</td>\n",
       "      <td>1.037868</td>\n",
       "      <td>-1.018123</td>\n",
       "      <td>-0.974632</td>\n",
       "      <td>0.041024</td>\n",
       "      <td>-0.772331</td>\n",
       "      <td>0.795409</td>\n",
       "      <td>-2.626333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    2.180118  5.013660  2.860423 -2.865401 -0.028288 -3.619290  0.292545   \n",
       "1   -0.472042  3.915963  2.068798 -5.190753  0.329500 -3.115555  4.373549   \n",
       "2   -0.667763  4.113233  0.487150  0.271637  3.015929  0.319480  3.013111   \n",
       "3   -0.120784 -0.306537  2.147649  1.115982 -2.374482 -2.725207 -1.637658   \n",
       "4   -4.884463 -4.142449  1.544765 -2.158188 -2.536783 -2.528181 -2.324859   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "764 -2.442063  4.145002  0.046409 -1.669268 -0.617231 -3.632627 -1.634848   \n",
       "765  0.669439 -0.016730  0.260739 -1.106865 -0.652408 -2.188516 -0.368060   \n",
       "766  1.013926  3.661481  1.313774 -0.589418 -2.415130 -0.546858  3.171532   \n",
       "767 -0.011871  0.952472 -1.284622  0.115353  0.384778 -0.522033  2.936195   \n",
       "768  1.339266 -2.163447  1.005169  1.037868 -1.018123 -0.974632  0.041024   \n",
       "\n",
       "            7         8         9  ...   36   37   38   39   40   41   42  \\\n",
       "0   -0.524740 -2.217012 -1.054117  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1    2.080570 -5.787605 -2.315120  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2    0.576483  0.880548 -2.119671  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3    1.236538 -0.551501 -3.421391  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4    3.421148 -1.575434 -0.027419  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "..        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "764  0.240459 -2.828122  0.877553  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "765  3.067914 -0.264205 -2.123014  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "766 -1.222912  3.141354 -1.771899  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "767  1.016842 -2.286952 -1.036577  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "768 -0.772331  0.795409 -2.626333  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      43   44  y  \n",
       "0    0.0  0.0  0  \n",
       "1    0.0  0.0  0  \n",
       "2    0.0  0.0  0  \n",
       "3    0.0  0.0  0  \n",
       "4    0.0  0.0  0  \n",
       "..   ...  ... ..  \n",
       "764  0.0  0.0  0  \n",
       "765  0.0  0.0  0  \n",
       "766  0.0  0.0  0  \n",
       "767  0.0  0.0  0  \n",
       "768  0.0  0.0  0  \n",
       "\n",
       "[769 rows x 46 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:51:37.581556Z",
     "start_time": "2022-04-30T20:51:37.568550Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x_train=train.iloc[:,:45]\n",
    "y_train=train['y']\n",
    "x_test=test.iloc[:,:45]\n",
    "y_test=test['y']\n",
    "\n",
    "\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "#y-layer is for y_train and x-layer is for x_train. I'm seperating both.\n",
    "#How? By selecting the first 45 columns for x_train and just the last column for y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:51:46.086006Z",
     "start_time": "2022-04-30T20:51:46.074140Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train=np.reshape(x_train,(x_train.shape[0],1,x_train.shape[1]))\n",
    "x_test=np.reshape(x_test,(x_test.shape[0],1,x_test.shape[1]))\n",
    "#Converting x_test and x_train into an LSTM standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:03.867567Z",
     "start_time": "2022-04-30T20:26:03.854600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:43:17.650848Z",
     "start_time": "2022-04-30T20:26:46.837875Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 1, 512)           618496    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_layer2 (LSTM)          (None, 128)               328192    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 30)                1950      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 957,215\n",
      "Trainable params: 957,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "102/102 - 8s - loss: 0.5888 - accuracy: 0.6796 - 8s/epoch - 81ms/step\n",
      "Epoch 2/100\n",
      "102/102 - 2s - loss: 0.5226 - accuracy: 0.7402 - 2s/epoch - 21ms/step\n",
      "Epoch 3/100\n",
      "102/102 - 2s - loss: 0.4888 - accuracy: 0.7638 - 2s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "102/102 - 2s - loss: 0.4659 - accuracy: 0.7750 - 2s/epoch - 17ms/step\n",
      "Epoch 5/100\n",
      "102/102 - 2s - loss: 0.4480 - accuracy: 0.7870 - 2s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "102/102 - 2s - loss: 0.4302 - accuracy: 0.7973 - 2s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "102/102 - 2s - loss: 0.4115 - accuracy: 0.8134 - 2s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "102/102 - 2s - loss: 0.3990 - accuracy: 0.8195 - 2s/epoch - 17ms/step\n",
      "Epoch 9/100\n",
      "102/102 - 2s - loss: 0.3830 - accuracy: 0.8255 - 2s/epoch - 17ms/step\n",
      "Epoch 10/100\n",
      "102/102 - 2s - loss: 0.3647 - accuracy: 0.8421 - 2s/epoch - 17ms/step\n",
      "Epoch 11/100\n",
      "102/102 - 2s - loss: 0.3568 - accuracy: 0.8409 - 2s/epoch - 17ms/step\n",
      "Epoch 12/100\n",
      "102/102 - 2s - loss: 0.3368 - accuracy: 0.8562 - 2s/epoch - 18ms/step\n",
      "Epoch 13/100\n",
      "102/102 - 2s - loss: 0.3281 - accuracy: 0.8565 - 2s/epoch - 18ms/step\n",
      "Epoch 14/100\n",
      "102/102 - 2s - loss: 0.3173 - accuracy: 0.8622 - 2s/epoch - 18ms/step\n",
      "Epoch 15/100\n",
      "102/102 - 2s - loss: 0.3035 - accuracy: 0.8683 - 2s/epoch - 18ms/step\n",
      "Epoch 16/100\n",
      "102/102 - 2s - loss: 0.2897 - accuracy: 0.8789 - 2s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "102/102 - 2s - loss: 0.2799 - accuracy: 0.8780 - 2s/epoch - 17ms/step\n",
      "Epoch 18/100\n",
      "102/102 - 2s - loss: 0.2713 - accuracy: 0.8849 - 2s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "102/102 - 2s - loss: 0.2617 - accuracy: 0.8838 - 2s/epoch - 17ms/step\n",
      "Epoch 20/100\n",
      "102/102 - 2s - loss: 0.2476 - accuracy: 0.8983 - 2s/epoch - 17ms/step\n",
      "Epoch 21/100\n",
      "102/102 - 2s - loss: 0.2418 - accuracy: 0.8969 - 2s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "102/102 - 2s - loss: 0.2363 - accuracy: 0.8992 - 2s/epoch - 17ms/step\n",
      "Epoch 23/100\n",
      "102/102 - 2s - loss: 0.2260 - accuracy: 0.9072 - 2s/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "102/102 - 2s - loss: 0.2224 - accuracy: 0.9076 - 2s/epoch - 17ms/step\n",
      "Epoch 25/100\n",
      "102/102 - 2s - loss: 0.2111 - accuracy: 0.9168 - 2s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "102/102 - 2s - loss: 0.2095 - accuracy: 0.9151 - 2s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "102/102 - 2s - loss: 0.1968 - accuracy: 0.9187 - 2s/epoch - 17ms/step\n",
      "Epoch 28/100\n",
      "102/102 - 2s - loss: 0.1915 - accuracy: 0.9185 - 2s/epoch - 17ms/step\n",
      "Epoch 29/100\n",
      "102/102 - 2s - loss: 0.1844 - accuracy: 0.9271 - 2s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "102/102 - 2s - loss: 0.1765 - accuracy: 0.9262 - 2s/epoch - 17ms/step\n",
      "Epoch 31/100\n",
      "102/102 - 2s - loss: 0.1761 - accuracy: 0.9294 - 2s/epoch - 17ms/step\n",
      "Epoch 32/100\n",
      "102/102 - 2s - loss: 0.1675 - accuracy: 0.9326 - 2s/epoch - 17ms/step\n",
      "Epoch 33/100\n",
      "102/102 - 2s - loss: 0.1572 - accuracy: 0.9349 - 2s/epoch - 17ms/step\n",
      "Epoch 34/100\n",
      "102/102 - 2s - loss: 0.1577 - accuracy: 0.9391 - 2s/epoch - 17ms/step\n",
      "Epoch 35/100\n",
      "102/102 - 2s - loss: 0.1459 - accuracy: 0.9415 - 2s/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "102/102 - 2s - loss: 0.1490 - accuracy: 0.9415 - 2s/epoch - 17ms/step\n",
      "Epoch 37/100\n",
      "102/102 - 2s - loss: 0.1426 - accuracy: 0.9421 - 2s/epoch - 17ms/step\n",
      "Epoch 38/100\n",
      "102/102 - 2s - loss: 0.1439 - accuracy: 0.9446 - 2s/epoch - 17ms/step\n",
      "Epoch 39/100\n",
      "102/102 - 2s - loss: 0.1354 - accuracy: 0.9474 - 2s/epoch - 17ms/step\n",
      "Epoch 40/100\n",
      "102/102 - 2s - loss: 0.1324 - accuracy: 0.9506 - 2s/epoch - 17ms/step\n",
      "Epoch 41/100\n",
      "102/102 - 2s - loss: 0.1235 - accuracy: 0.9537 - 2s/epoch - 18ms/step\n",
      "Epoch 42/100\n",
      "102/102 - 2s - loss: 0.1188 - accuracy: 0.9537 - 2s/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "102/102 - 2s - loss: 0.1180 - accuracy: 0.9550 - 2s/epoch - 18ms/step\n",
      "Epoch 44/100\n",
      "102/102 - 2s - loss: 0.1156 - accuracy: 0.9564 - 2s/epoch - 17ms/step\n",
      "Epoch 45/100\n",
      "102/102 - 2s - loss: 0.1065 - accuracy: 0.9619 - 2s/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "102/102 - 2s - loss: 0.1044 - accuracy: 0.9616 - 2s/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "102/102 - 2s - loss: 0.1047 - accuracy: 0.9598 - 2s/epoch - 17ms/step\n",
      "Epoch 48/100\n",
      "102/102 - 2s - loss: 0.0999 - accuracy: 0.9629 - 2s/epoch - 18ms/step\n",
      "Epoch 49/100\n",
      "102/102 - 2s - loss: 0.0960 - accuracy: 0.9639 - 2s/epoch - 18ms/step\n",
      "Epoch 50/100\n",
      "102/102 - 2s - loss: 0.0918 - accuracy: 0.9675 - 2s/epoch - 17ms/step\n",
      "Epoch 51/100\n",
      "102/102 - 2s - loss: 0.0911 - accuracy: 0.9642 - 2s/epoch - 17ms/step\n",
      "Epoch 52/100\n",
      "102/102 - 2s - loss: 0.0873 - accuracy: 0.9701 - 2s/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "102/102 - 2s - loss: 0.0852 - accuracy: 0.9679 - 2s/epoch - 17ms/step\n",
      "Epoch 54/100\n",
      "102/102 - 2s - loss: 0.0849 - accuracy: 0.9695 - 2s/epoch - 18ms/step\n",
      "Epoch 55/100\n",
      "102/102 - 2s - loss: 0.0787 - accuracy: 0.9725 - 2s/epoch - 17ms/step\n",
      "Epoch 56/100\n",
      "102/102 - 2s - loss: 0.0740 - accuracy: 0.9754 - 2s/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "102/102 - 2s - loss: 0.0759 - accuracy: 0.9739 - 2s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "102/102 - 2s - loss: 0.0733 - accuracy: 0.9751 - 2s/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "102/102 - 2s - loss: 0.0680 - accuracy: 0.9762 - 2s/epoch - 17ms/step\n",
      "Epoch 60/100\n",
      "102/102 - 2s - loss: 0.0633 - accuracy: 0.9800 - 2s/epoch - 17ms/step\n",
      "Epoch 61/100\n",
      "102/102 - 2s - loss: 0.0642 - accuracy: 0.9785 - 2s/epoch - 17ms/step\n",
      "Epoch 62/100\n",
      "102/102 - 2s - loss: 0.0613 - accuracy: 0.9779 - 2s/epoch - 17ms/step\n",
      "Epoch 63/100\n",
      "102/102 - 2s - loss: 0.0597 - accuracy: 0.9814 - 2s/epoch - 17ms/step\n",
      "Epoch 64/100\n",
      "102/102 - 2s - loss: 0.0646 - accuracy: 0.9796 - 2s/epoch - 17ms/step\n",
      "Epoch 65/100\n",
      "102/102 - 2s - loss: 0.0707 - accuracy: 0.9764 - 2s/epoch - 18ms/step\n",
      "Epoch 66/100\n",
      "102/102 - 2s - loss: 0.0598 - accuracy: 0.9811 - 2s/epoch - 17ms/step\n",
      "Epoch 67/100\n",
      "102/102 - 2s - loss: 0.0508 - accuracy: 0.9842 - 2s/epoch - 17ms/step\n",
      "Epoch 68/100\n",
      "102/102 - 2s - loss: 0.0498 - accuracy: 0.9856 - 2s/epoch - 18ms/step\n",
      "Epoch 69/100\n",
      "102/102 - 2s - loss: 0.0578 - accuracy: 0.9808 - 2s/epoch - 18ms/step\n",
      "Epoch 70/100\n",
      "102/102 - 2s - loss: 0.0551 - accuracy: 0.9833 - 2s/epoch - 17ms/step\n",
      "Epoch 71/100\n",
      "102/102 - 2s - loss: 0.0495 - accuracy: 0.9836 - 2s/epoch - 17ms/step\n",
      "Epoch 72/100\n",
      "102/102 - 2s - loss: 0.0492 - accuracy: 0.9840 - 2s/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "102/102 - 2s - loss: 0.0467 - accuracy: 0.9862 - 2s/epoch - 18ms/step\n",
      "Epoch 74/100\n",
      "102/102 - 2s - loss: 0.0539 - accuracy: 0.9836 - 2s/epoch - 18ms/step\n",
      "Epoch 75/100\n",
      "102/102 - 2s - loss: 0.0508 - accuracy: 0.9845 - 2s/epoch - 18ms/step\n",
      "Epoch 76/100\n",
      "102/102 - 2s - loss: 0.0449 - accuracy: 0.9866 - 2s/epoch - 18ms/step\n",
      "Epoch 77/100\n",
      "102/102 - 2s - loss: 0.0470 - accuracy: 0.9857 - 2s/epoch - 17ms/step\n",
      "Epoch 78/100\n",
      "102/102 - 2s - loss: 0.0458 - accuracy: 0.9857 - 2s/epoch - 17ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "102/102 - 2s - loss: 0.0417 - accuracy: 0.9874 - 2s/epoch - 17ms/step\n",
      "Epoch 80/100\n",
      "102/102 - 2s - loss: 0.0462 - accuracy: 0.9859 - 2s/epoch - 18ms/step\n",
      "Epoch 81/100\n",
      "102/102 - 2s - loss: 0.0424 - accuracy: 0.9876 - 2s/epoch - 17ms/step\n",
      "Epoch 82/100\n",
      "102/102 - 2s - loss: 0.0463 - accuracy: 0.9862 - 2s/epoch - 17ms/step\n",
      "Epoch 83/100\n",
      "102/102 - 2s - loss: 0.0414 - accuracy: 0.9873 - 2s/epoch - 17ms/step\n",
      "Epoch 84/100\n",
      "102/102 - 2s - loss: 0.0426 - accuracy: 0.9879 - 2s/epoch - 17ms/step\n",
      "Epoch 85/100\n",
      "102/102 - 2s - loss: 0.0499 - accuracy: 0.9836 - 2s/epoch - 17ms/step\n",
      "Epoch 86/100\n",
      "102/102 - 2s - loss: 0.0413 - accuracy: 0.9882 - 2s/epoch - 17ms/step\n",
      "Epoch 87/100\n",
      "102/102 - 2s - loss: 0.0390 - accuracy: 0.9871 - 2s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "102/102 - 2s - loss: 0.0367 - accuracy: 0.9886 - 2s/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "102/102 - 2s - loss: 0.0410 - accuracy: 0.9883 - 2s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "102/102 - 2s - loss: 0.0388 - accuracy: 0.9882 - 2s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "102/102 - 2s - loss: 0.0333 - accuracy: 0.9908 - 2s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "102/102 - 2s - loss: 0.0353 - accuracy: 0.9905 - 2s/epoch - 18ms/step\n",
      "Epoch 93/100\n",
      "102/102 - 2s - loss: 0.0400 - accuracy: 0.9888 - 2s/epoch - 18ms/step\n",
      "Epoch 94/100\n",
      "102/102 - 2s - loss: 0.0288 - accuracy: 0.9922 - 2s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "102/102 - 2s - loss: 0.0422 - accuracy: 0.9886 - 2s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "102/102 - 2s - loss: 0.0386 - accuracy: 0.9894 - 2s/epoch - 18ms/step\n",
      "Epoch 97/100\n",
      "102/102 - 2s - loss: 0.0340 - accuracy: 0.9914 - 2s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "102/102 - 2s - loss: 0.0399 - accuracy: 0.9890 - 2s/epoch - 18ms/step\n",
      "Epoch 99/100\n",
      "102/102 - 2s - loss: 0.0369 - accuracy: 0.9896 - 2s/epoch - 17ms/step\n",
      "Epoch 100/100\n",
      "102/102 - 2s - loss: 0.0339 - accuracy: 0.9920 - 2s/epoch - 17ms/step\n",
      "25/25 - 1s - loss: 0.9613 - accuracy: 0.8062 - 922ms/epoch - 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9612648487091064, 0.8062418699264526]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(keras.Input(shape=(x_train.shape[1],1)))\n",
    "\n",
    "model.add(keras.Input(shape=(1,x_train.shape[2])))\n",
    "\n",
    "model.add(layers.Bidirectional(layers.LSTM(256, return_sequences=True, activation=\"relu\")))\n",
    "\n",
    "model.add(layers.LSTM(128, name=\"lstm_layer2\"))\n",
    "\n",
    "# model.add(LSTM(512, activation='exponential'))\n",
    "model.add(layers.Dense(64, activation='exponential'))\n",
    "\n",
    "model.add(layers.Dense(30,activation='hard_sigmoid'))\n",
    "\n",
    "model.add(layers.Dense(10,activation='tanh'))\n",
    "\n",
    "# model.add(layers.Dense(16,activation='hard_sigmoid'))\n",
    "\n",
    "# model.add(LSTM(64, activation='exponential'))\n",
    "# model.add(layers.Dense(10,activation='hard_sigmoid'))\n",
    "# model.add(layers.Dense(10,activation='tanh'))\n",
    "\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=100, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n",
    "\n",
    "#LSTM Model trained and then used for testing\n",
    "#100 epochs gives a decent enough score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:04.919363Z",
     "start_time": "2022-04-30T20:25:48.874Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# # model.add(LSTM(100, activation='tanh', return_sequences=True, input_shape=(1, x_train.shape[1])))\n",
    "# model.add(layers.Bidirectional(layers.LSTM(500, return_sequences=True, activation=\"tanh\",input_shape=(1, x_train.shape[2]))))\n",
    "# model.add(LSTM(300, activation='tanh'))\n",
    "# model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(optimizer=\"rmsprop\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(x_train,y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:51:55.948040Z",
     "start_time": "2022-04-30T20:51:54.706715Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15128/2733949168.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#Invoking LSTM's predicting function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "o=model.predict(x_test)\n",
    "#Invoking LSTM's predicting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:04.924318Z",
     "start_time": "2022-04-30T20:25:48.883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round(o[4][0])\n",
    "# Rounding to the nearest number!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:52:04.725714Z",
     "start_time": "2022-04-30T20:52:04.683594Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_prep=[]\n",
    "for i in range(len(o)):\n",
    "    Y_prep.append(round(o[i][0]))\n",
    "# Rounding to the nearest number!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:52:13.431952Z",
     "start_time": "2022-04-30T20:52:13.352202Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[616 153]\n",
      " [145 624]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,Y_prep)\n",
    "print (confusion_matrix)\n",
    "#Confusion matrix for plotting the results and calculating the accuracy\n",
    "#Top left corner is idiom predictions\n",
    "#Bottom right corner is for literal predictions\n",
    "#Bottom left and top right are incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct idiomatic classification :  0.8010403120936281\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage correct idiomatic classification : \" , 616/(616+153))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct literal classification :  0.811443433029909\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage correct literal classification : \" , 624/(624+145))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage correct literal classification : \" , 624/(624+145))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall percentage correct classification :  0.8062418725617685\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall percentage correct classification : \" , (624+616)/(616+153+145+624))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23504/2328055408.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mfinal_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfinal_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "def accuracy_score(confusion_matrix):\n",
    "    final_score = (confusion_matrix[0,0]+confusion_matrix[1,1])/confusion_matrix.sum()\n",
    "    return final_score\n",
    "accuracy_score(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "# X, y = make_classification(random_state=0)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# clf = SVC(random_state=0)\n",
    "# clf.fit(X_train, y_train)\n",
    "# SVC(random_state=0)\n",
    "# plot_confusion_matrix(model, Y_prep, y_test)  \n",
    "# plt.show()\n",
    "\n",
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, Y_prep)\n",
    "f = sns.heatmap(cm, annot=True, fmt='d')\n",
    "#Plotting the grapth in a better, more visual way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1538"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:53:03.910985Z",
     "start_time": "2022-04-30T20:53:03.897991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8062418725617685"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(616  + 624)/(confusion_matrix.sum())#Idiomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:04.932329Z",
     "start_time": "2022-04-30T20:25:48.891Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(718+497)/(769*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:04.933292Z",
     "start_time": "2022-04-30T20:25:48.893Z"
    }
   },
   "outputs": [],
   "source": [
    "601/769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:04.935289Z",
     "start_time": "2022-04-30T20:25:48.894Z"
    }
   },
   "outputs": [],
   "source": [
    "657/(657+112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:04.939294Z",
     "start_time": "2022-04-30T20:25:48.897Z"
    }
   },
   "outputs": [],
   "source": [
    "(641+601)/confusion_matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:04.941271Z",
     "start_time": "2022-04-30T20:25:48.899Z"
    }
   },
   "outputs": [],
   "source": [
    "(613+616)/(769*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:04.944265Z",
     "start_time": "2022-04-30T20:25:48.902Z"
    }
   },
   "outputs": [],
   "source": [
    "(564+635)/(769*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T20:26:04.947255Z",
     "start_time": "2022-04-30T20:25:48.905Z"
    }
   },
   "outputs": [],
   "source": [
    "(657+571)/(769*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
